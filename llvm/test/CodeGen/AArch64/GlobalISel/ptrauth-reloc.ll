; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple arm64e-apple-darwin     -global-isel -verify-machineinstrs -global-isel-abort=1 -aarch64-ptrauth-global-dynamic-mat=1 | FileCheck %s --check-prefixes=CHECK,DYN
; RUN: llc < %s -mtriple arm64e-apple-darwin     -global-isel -verify-machineinstrs -global-isel-abort=1 -aarch64-ptrauth-global-dynamic-mat=0 | FileCheck %s --check-prefixes=CHECK,LOAD

target datalayout = "e-m:o-i64:64-i128:128-n32:64-S128"

; Check code references.

define i8* @test_global_zero_disc() {
; DYN-LABEL: test_global_zero_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:  Lloh0:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:  Lloh1:
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    paciza x16
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
; DYN-NEXT:    .loh AdrpLdrGot Lloh0, Lloh1
;
; LOAD-LABEL: test_global_zero_disc:
; LOAD:       ; %bb.0:
; LOAD-NEXT:  Lloh0:
; LOAD-NEXT:    adrp x0, l_g$auth_ptr$ia$0@PAGE
; LOAD-NEXT:  Lloh1:
; LOAD-NEXT:    ldr x0, [x0, l_g$auth_ptr$ia$0@PAGEOFF]
; LOAD-NEXT:    ret
; LOAD-NEXT:    .loh AdrpLdr Lloh0, Lloh1
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.ia.0 to i8*
  ret i8* %tmp0
}

define i8* @test_global_offset_zero_disc() {
; DYN-LABEL: test_global_offset_zero_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:  Lloh2:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:  Lloh3:
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    add x16, x16, #16 ; =16
; DYN-NEXT:    pacdza x16
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
; DYN-NEXT:    .loh AdrpLdrGot Lloh2, Lloh3
;
; LOAD-LABEL: test_global_offset_zero_disc:
; LOAD:       ; %bb.0:
; LOAD-NEXT:  Lloh2:
; LOAD-NEXT:    adrp x0, l_g$16$auth_ptr$da$0@PAGE
; LOAD-NEXT:  Lloh3:
; LOAD-NEXT:    ldr x0, [x0, l_g$16$auth_ptr$da$0@PAGEOFF]
; LOAD-NEXT:    ret
; LOAD-NEXT:    .loh AdrpLdr Lloh2, Lloh3
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.offset.ptrauth.da.0 to i8*
  ret i8* %tmp0
}

; For large offsets, materializing it can take up to 3 add instructions.
; We limit the offset to 32-bits.  We theoretically could support up to
; 64 bit offsets, but 32 bits Ought To Be Enough For Anybody, and that's
; the limit for the relocation addend anyway.
; But we never use the stub and relocation because of dyld shared cache
; encoding constraints.

define i8* @test_global_big_offset_zero_disc() {
; CHECK-LABEL: test_global_big_offset_zero_disc:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh4:
; CHECK-NEXT:    adrp x16, _g@GOTPAGE
; CHECK-NEXT:  Lloh5:
; CHECK-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; CHECK-NEXT:    add x16, x16, #1 ; =1
; CHECK-NEXT:    add x16, x16, #16, lsl #12 ; =65536
; CHECK-NEXT:    add x16, x16, #128, lsl #24 ; =2147483648
; CHECK-NEXT:    pacdza x16
; CHECK-NEXT:    mov x0, x16
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdrGot Lloh4, Lloh5
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.big_offset.ptrauth.da.0 to i8*
  ret i8* %tmp0
}

define i8* @test_global_disc() {
; DYN-LABEL: test_global_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:  Lloh6:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:  Lloh7:
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    mov x17, #42
; DYN-NEXT:    pacia x16, x17
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
; DYN-NEXT:    .loh AdrpLdrGot Lloh6, Lloh7
;
; LOAD-LABEL: test_global_disc:
; LOAD:       ; %bb.0:
; LOAD-NEXT:  Lloh6:
; LOAD-NEXT:    adrp x0, l_g$auth_ptr$ia$42@PAGE
; LOAD-NEXT:  Lloh7:
; LOAD-NEXT:    ldr x0, [x0, l_g$auth_ptr$ia$42@PAGEOFF]
; LOAD-NEXT:    ret
; LOAD-NEXT:    .loh AdrpLdr Lloh6, Lloh7
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.ia.42 to i8*
  ret i8* %tmp0
}

define i8* @test_global_addr_disc() {
; DYN-LABEL: test_global_addr_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:  Lloh8:
; DYN-NEXT:    adrp x8, _g.ref.da.42.addr@PAGE
; DYN-NEXT:  Lloh9:
; DYN-NEXT:    add x8, x8, _g.ref.da.42.addr@PAGEOFF
; DYN-NEXT:  Lloh10:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:  Lloh11:
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    mov x17, x8
; DYN-NEXT:    movk x17, #42, lsl #48
; DYN-NEXT:    pacda x16, x17
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
; DYN-NEXT:    .loh AdrpLdrGot Lloh10, Lloh11
; DYN-NEXT:    .loh AdrpAdd Lloh8, Lloh9
;
; LOAD-LABEL: test_global_addr_disc:
; LOAD:       ; %bb.0:
; LOAD-NEXT:  Lloh8:
; LOAD-NEXT:    adrp x8, _g.ref.da.42.addr@PAGE
; LOAD-NEXT:  Lloh9:
; LOAD-NEXT:    add x8, x8, _g.ref.da.42.addr@PAGEOFF
; LOAD-NEXT:  Lloh10:
; LOAD-NEXT:    adrp x16, l_g$auth_ptr$da$42@PAGE
; LOAD-NEXT:  Lloh11:
; LOAD-NEXT:    ldr x16, [x16, l_g$auth_ptr$da$42@PAGEOFF]
; LOAD-NEXT:    mov x17, #42
; LOAD-NEXT:    autda x16, x17
; LOAD-NEXT:    mov x17, x16
; LOAD-NEXT:    xpacd x17
; LOAD-NEXT:    cmp x16, x17
; LOAD-NEXT:    b.eq Lauth_success_0
; LOAD-NEXT:    mov x16, x17
; LOAD-NEXT:    b Lresign_end_0
; LOAD-NEXT:  Lauth_success_0:
; LOAD-NEXT:    mov x17, x8
; LOAD-NEXT:    movk x17, #42, lsl #48
; LOAD-NEXT:    pacda x16, x17
; LOAD-NEXT:  Lresign_end_0:
; LOAD-NEXT:    mov x0, x16
; LOAD-NEXT:    ret
; LOAD-NEXT:    .loh AdrpLdr Lloh10, Lloh11
; LOAD-NEXT:    .loh AdrpAdd Lloh8, Lloh9
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.da.42.addr to i8*
  ret i8* %tmp0
}

; Process-specific keys can't use __DATA,__auth_ptr

define i8* @test_global_process_specific() {
; DYN-LABEL: test_global_process_specific:
; DYN:       ; %bb.0:
; DYN-NEXT:  Lloh12:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:  Lloh13:
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    pacizb x16
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
; DYN-NEXT:    .loh AdrpLdrGot Lloh12, Lloh13
;
; LOAD-LABEL: test_global_process_specific:
; LOAD:       ; %bb.0:
; LOAD-NEXT:  Lloh12:
; LOAD-NEXT:    adrp x16, l_g$auth_ptr$ia$0@PAGE
; LOAD-NEXT:  Lloh13:
; LOAD-NEXT:    ldr x16, [x16, l_g$auth_ptr$ia$0@PAGEOFF]
; LOAD-NEXT:    autiza x16
; LOAD-NEXT:    mov x17, x16
; LOAD-NEXT:    xpaci x17
; LOAD-NEXT:    cmp x16, x17
; LOAD-NEXT:    b.eq Lauth_success_1
; LOAD-NEXT:    mov x16, x17
; LOAD-NEXT:    b Lresign_end_1
; LOAD-NEXT:  Lauth_success_1:
; LOAD-NEXT:    pacizb x16
; LOAD-NEXT:  Lresign_end_1:
; LOAD-NEXT:    mov x0, x16
; LOAD-NEXT:    ret
; LOAD-NEXT:    .loh AdrpLdr Lloh12, Lloh13
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.ib.0 to i8*
  ret i8* %tmp0
}

; weak symbols can't be assumed to be non-nil.  Use __DATA,__auth_ptr always.
; The alternative is to emit a null-check here, but that'd be redundant with
; whatever null-check follows in user code.

define i8* @test_global_weak() {
; CHECK-LABEL: test_global_weak:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh14:
; CHECK-NEXT:    adrp x0, l_g_weak$auth_ptr$ia$42@PAGE
; CHECK-NEXT:  Lloh15:
; CHECK-NEXT:    ldr x0, [x0, l_g_weak$auth_ptr$ia$42@PAGEOFF]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdr Lloh14, Lloh15
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g_weak.ptrauth.ia.42 to i8*
  ret i8* %tmp0
}

; Non-external symbols don't need to be accessed through the GOT: always prefer
; the dynamic materialization sequence, with adrp+add rather than a GOT load.

define i8* @test_global_strong_def() {
; CHECK-LABEL: test_global_strong_def:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh16:
; CHECK-NEXT:    adrp x16, _g_strong_def@PAGE
; CHECK-NEXT:  Lloh17:
; CHECK-NEXT:    add x16, x16, _g_strong_def@PAGEOFF
; CHECK-NEXT:    pacdza x16
; CHECK-NEXT:    mov x0, x16
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh16, Lloh17
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g_strong_def.ptrauth.da.0 to i8*
  ret i8* %tmp0
}

; Check global references.

@g = external global i32

@g_weak = extern_weak global i32

@g_strong_def = constant i32 42

; CHECK-LABEL:   .section __DATA,__const
; CHECK-NEXT:    .globl _g.ref.ia.0
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  _g.ref.ia.0:
; CHECK-NEXT:    .quad 5
; CHECK-NEXT:    .quad _g@AUTH(ia,0)
; CHECK-NEXT:    .quad 6

@g.ptrauth.ia.0 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 0, i64 0, i64 0 }, section "llvm.ptrauth"

@g.ref.ia.0 = constant { i64, i8*, i64 } { i64 5, i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.ia.0 to i8*), i64 6 }

; CHECK-LABEL:   .globl _g.ref.ia.42
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.ref.ia.42:
; CHECK-NEXT:    .quad _g@AUTH(ia,42)

@g.ptrauth.ia.42 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 0, i64 0, i64 42 }, section "llvm.ptrauth"

@g.ref.ia.42 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.ia.42 to i8*)

; CHECK-LABEL:   .globl _g.ref.ib.0
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  _g.ref.ib.0:
; CHECK-NEXT:    .quad 5
; CHECK-NEXT:    .quad _g@AUTH(ib,0)
; CHECK-NEXT:    .quad 6

@g.ptrauth.ib.0 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 1, i64 0, i64 0 }, section "llvm.ptrauth"

@g.ref.ib.0 = constant { i64, i8*, i64 } { i64 5, i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.ib.0 to i8*), i64 6 }


; CHECK-LABEL:   .globl _g.ref.da.42.addr
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.ref.da.42.addr:
; CHECK-NEXT:    .quad _g@AUTH(da,42,addr)

@g.ptrauth.da.42.addr = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 2, i64 ptrtoint (i8** @g.ref.da.42.addr to i64), i64 42 }, section "llvm.ptrauth"

@g.ref.da.42.addr = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.da.42.addr to i8*)

; CHECK-LABEL:   .globl _g.offset.ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.offset.ref.da.0:
; CHECK-NEXT:    .quad (_g+16)@AUTH(da,0)

@g.offset.ptrauth.da.0 = private constant { i8*, i32, i64, i64 } { i8* getelementptr (i8, i8* bitcast (i32* @g to i8*), i64 16), i32 2, i64 0, i64 0 }, section "llvm.ptrauth"

@g.offset.ref.da.0 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.offset.ptrauth.da.0 to i8*)

; CHECK-LABEL:   .globl _g.big_offset.ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.big_offset.ref.da.0:
; CHECK-NEXT:    .quad (_g+2147549185)@AUTH(da,0)

@g.big_offset.ptrauth.da.0 = private constant { i8*, i32, i64, i64 } { i8* getelementptr (i8, i8* bitcast (i32* @g to i8*), i64 add (i64 2147483648, i64 65537)), i32 2, i64 0, i64 0 }, section "llvm.ptrauth"

@g.big_offset.ref.da.0 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.big_offset.ptrauth.da.0 to i8*)

; CHECK-LABEL:   .globl _g.weird_ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.weird_ref.da.0:
; CHECK-NEXT:    .quad (_g+16)@AUTH(da,0)

@g.weird_ref.da.0 = constant i64 ptrtoint (i8* bitcast (i64* inttoptr (i64 ptrtoint (i8* bitcast ({ i8*, i32, i64, i64 }* @g.offset.ptrauth.da.0 to i8*) to i64) to i64*) to i8*) to i64)

; CHECK-LABEL:   .globl _g_weak.ref.ia.42
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g_weak.ref.ia.42:
; CHECK-NEXT:    .quad _g_weak@AUTH(ia,42)

@g_weak.ptrauth.ia.42 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g_weak to i8*), i32 0, i64 0, i64 42 }, section "llvm.ptrauth"

@g_weak.ref.ia.42 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g_weak.ptrauth.ia.42 to i8*)

; CHECK-LABEL:   .globl _g_strong_def.ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g_strong_def.ref.da.0:
; CHECK-NEXT:    .quad _g_strong_def@AUTH(da,0)

@g_strong_def.ptrauth.da.0 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g_strong_def to i8*), i32 2, i64 0, i64 0 }, section "llvm.ptrauth"

@g_strong_def.ref.da.0 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g_strong_def.ptrauth.da.0 to i8*)
